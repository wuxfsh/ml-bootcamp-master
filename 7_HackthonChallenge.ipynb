{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML bootcamp hackthon challenge: sentiment analysis\n",
    "\n",
    "At this stage you have learned what machine learning is and you have seen examples of how to use machine learning. Now it is time to see how well YOU can generalize what you have learned to a new challenge.\n",
    "\n",
    "The hackathon has two tracks: in the **Ideation Track** you can brainstorm on what great apps we can build for the enterprise with this new technology. What are the 'jobs to be done' that machine learning can solve for us in the future? Create an Intrapreneurship-style pitch and present it to the team on Friday. \n",
    "https://jam4.sapjam.com/groups/r7ILMAl5MxS8rgHSaNR8L9/overview_page/46399\n",
    "\n",
    "In the **Data Science Track**, we will run a hackthon challenge on a popular machine learning task: predicting consumer sentiment from online reviews. You are given a set of movie reviews and their labels (positive, negative) and you have to build a system that can predict the sentiment for a new movie review.\n",
    "\n",
    "We are using the popular polarity data set from Cornell University.\n",
    "http://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## download the movie review data set\n",
    "import sys, os \n",
    "import urllib.request\n",
    "\n",
    "# set http proxy env variable\n",
    "import os\n",
    "os.environ['http_proxy'] = 'proxy.sin.sap.corp:8080'\n",
    "\n",
    "# download file to /tmp\n",
    "url = \"http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\"\n",
    "file_name = '/tmp/review_polarity.tar.gz'\n",
    "if not os.path.isfile(file_name):\n",
    "    with urllib.request.urlopen(url) as response, open(file_name, 'wb') as out_file:\n",
    "        data = response.read() # a `bytes` object\n",
    "        out_file.write(data)\n",
    "    out_file.close()\n",
    "\n",
    "# make file world readable\n",
    "os.chmod(file_name, 0o755)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract file to /tmp dir\n",
    "import tarfile\n",
    "import os.path\n",
    "\n",
    "\n",
    "if not os.path.isdir('/tmp/txt_sentoken'):\n",
    "    os.chdir('/tmp')\n",
    "    tar = tarfile.open(file_name, \"r:gz\")\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "    \n",
    "\n",
    "# make files world readable\n",
    "for label in ['pos', 'neg']:\n",
    "    os.chmod('/tmp/txt_sentoken/%s/' % label, 0o755)\n",
    "    for file_name in os.listdir('/tmp/txt_sentoken/%s/' % label):\n",
    "        os.chmod(os.path.join('/tmp/txt_sentoken/%s/' % label, file_name), 0o755)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load positive and negative movie review text\n",
    "\n",
    "# list to store the examples\n",
    "reviews = []\n",
    "\n",
    "# load positive reviews\n",
    "for file_name in os.listdir('/tmp/txt_sentoken/pos/'):\n",
    "    with open(os.path.join('/tmp/txt_sentoken/pos/', file_name)) as fin:\n",
    "        # append sentiment 'pos' label and review text\n",
    "        reviews.append(('pos', fin.read()))\n",
    "        \n",
    "# load negative reviews\n",
    "for file_name in os.listdir('/tmp/txt_sentoken/neg/'):\n",
    "    with open(os.path.join('/tmp/txt_sentoken/neg/', file_name)) as fin:\n",
    "        # append sentiment 'neg' label and review text\n",
    "        reviews.append(('neg', fin.read()))\n",
    "\n",
    "# great, there are 2000 reviews in the data set now  \n",
    "print(len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# randomly split data into 80% training and 20% testing\n",
    "# each example is a tuple consisting of a (pos/neg)  sentiment label \n",
    "# and the text of the review\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(reviews)\n",
    "\n",
    "size_train = int(len(reviews)*0.8)\n",
    "reviews_train = reviews[:size_train]\n",
    "reviews_test = reviews[size_train:]\n",
    "\n",
    "print(\"size of training set:\", len(reviews_train))\n",
    "print(\"size of test set:\", len(reviews_test))\n",
    "\n",
    "# split data and text\n",
    "labels_train = [ item[0] for item in reviews_train ]\n",
    "corpus_train = [ item[1] for item in reviews_train]\n",
    "\n",
    "labels_test = [ item[0] for item in reviews_test ]\n",
    "corpus_test = [ item[1] for item in reviews_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's look at a few examples of the training set\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=3)\n",
    "pp.pprint(reviews_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 1: data rookie\n",
    "Explore the data and find out which words are good features for positive and negative reviews. Visualize the data. Remember what you have learned in the text mining notebook about pre-processing for text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## pre-process, visualize and exploree data\n",
    "\n",
    "#  YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2: data sophomore\n",
    "Build a first classifier that can predict if a given movie review is positive or negative. \n",
    "Remember what you have learned in the data science and text mining notebooks about feature extraction pipelines, training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## feature extraction, model training on the training set and evaluation on the test set using accuracy\n",
    "\n",
    "#  YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 3: data ninja\n",
    "Improve your classifier, try out different pre-processing steps, features, classifier models, etc. \n",
    "Let's see who can build the most accurate classifier!!\n",
    "Let's the games begin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## build pipelines to test different pre-processing, feaature extraction, and machine learning models\n",
    "## try to get the best accuracy on the test set\n",
    "\n",
    "#  YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Level 4: the architect\n",
    "Build an end-to-end system with REST APIs for sentiment analysis. Input is a movie review, output is the model prediction. You can stay withing python or use the software stack of your trust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Level 5: the artist\n",
    "Design a beautiful user experience how the predicted labels of the algorithm can be presented to a consumer on a mobile device. Connect it to the REST webservice or just mock up the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
